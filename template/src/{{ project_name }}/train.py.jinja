import os
import lightning as L
from omegaconf import DictConfig
import hydra
from {{ project_name }}.model import Encoder, Decoder, VAE
from {{ project_name }}.dataloader import MNISTDataModule
from lightning.pytorch.callbacks import EarlyStopping
from lightning.pytorch.loggers import TensorBoardLogger


@hydra.main(version_base=None, config_path="conf", config_name="config")
def train(cfg: DictConfig) -> int:
    logger = TensorBoardLogger(cfg.data.logs_dir, name="autoencoder")

    # model
    autoencoder = VAE(cfg.data.latent_dim, cfg.optim.lr)

    data_module = MNISTDataModule(
        data_dir=cfg.data.data_dir,
        batch_size=cfg.data.batch_size,
        num_workers=cfg.data.num_workers,
    )

    # train model
    trainer = L.Trainer(
        logger=logger,
        accelerator=cfg.train.accelerator,
        default_root_dir=cfg.data.logs_dir,
        min_epochs=1,
        max_epochs=cfg.train.epochs,
        callbacks=[EarlyStopping(monitor="val_loss")],
    )
    trainer.fit(autoencoder, data_module)
    trainer.validate(autoencoder, data_module)

    return os.EX_OK


if __name__ == "__main__":
    train()
